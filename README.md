#  Heart Disease Prediction using Decision Trees and Random Forests

##  Overview
This project demonstrates the use of **tree-based models** — including **Decision Trees** and **Random Forests** — to predict the presence of **heart disease**. The task includes model training, visualization, evaluation, and interpretation using **Scikit-learn** and **Matplotlib**.

---

##  Objectives
- Train and visualize a **Decision Tree Classifier**
- Understand and mitigate **overfitting** by limiting tree depth
- Train a **Random Forest Classifier** and compare its performance
- Interpret **feature importances**
- Evaluate model performance using **cross-validation**

---

##  Tools & Libraries
- Python (Jupyter Notebook)
- Pandas
- Scikit-learn
- Matplotlib
- Seaborn

---

##  File Structure
├── heart_disease.csv # Dataset used for training and evaluation
├── Heart_Disease_Tree_Models.ipynb # Jupyter notebook with full implementation
└── README.md # Project documentation

---

##  Dataset Description
**Heart Disease Dataset**  
Each row represents a patient with features like:
- `age`, `sex`, `cp` (chest pain type), `chol` (cholesterol), `thalach` (max heart rate), etc.  
- Target: `1` = heart disease present, `0` = no heart disease.

---

##  Evaluation Metrics
- **Accuracy Score**
- **Confusion Matrix**
- **Cross-validation Accuracy**
- **Feature Importance Visualization**

---

##  Visualizations
- Decision Tree plotted using `plot_tree()`
- Bar chart for **feature importances** using Random Forest

---

##  What You'll Learn
- How Decision Trees split data to make predictions
- How to prevent overfitting by limiting depth
- The concept of **ensemble learning** using Random Forests
- How to interpret model behavior through **feature importances**
- Evaluating models with **cross-validation**

---

##  How to Run
1. Clone or download the repository
2. Place the `heart_disease.csv` file in the same directory
3. Open the `Heart_Disease_Tree_Models.ipynb` notebook in Jupyter
4. Run all cells sequentially

---


